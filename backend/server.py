# -*- coding: utf-8 -*-
"""Fliprr25 (1).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1FmkRPBxwTb9EvxIdl3pS9lXpYI7LpGDp
"""

from SRC.Summary_Generator import *
from SRC.Prompts import system_prompt, merge_prompt
from SRC.Helper_func import *

import yaml
from flask import Flask, jsonify
from flask_cors import CORS
import json
import os
import ssl
ssl._create_default_https_context = ssl._create_unverified_context

app = Flask(__name__)
CORS(app)  

# Load the YAML file
with open('configs.yaml', 'r') as file:
    config = yaml.safe_load(file)

# Accessing the data
topic = config['topic']
location = config['location']

gemini_api_key = "AIzaSyBcWlg4ghR-UC9q_KCCOeo9Lxwy5dcuWB4"
serp_api_key = "86ed0f9b53704a3a98a7a9ca56262ec9d9771bf2ebc3d87ddb02015653f6359d"
# genai.configure(api_key=gemini_api_key)
agent = NewsAgent1(
    system_prompt=system_prompt,
    location=location,
    topic=topic,
    gemini_api_key=gemini_api_key,
    serp_api_key=serp_api_key,
)
print("topic",topic)
# Process unique news and get DataFrame
news_df = agent.process_news(num_links=8) # news_df -> top15 news of that topic
print("Len of news df")
print(news_df.shape[0])
df = news_df['full_text']
texts = []
for i in df:
    texts.append(i['description'])
a = NewsFilter(threshold=0.75)
unique_news_indices = a.filter_unique_texts(texts)
# print(unique_news_indices)
print("unique_news_indices", unique_news_indices)

NewsSummaries = []
for i in unique_news_indices:
    topic = df[i]['description']
    agent = NewsAgent2(merge_prompt=merge_prompt,
                       system_prompt=system_prompt,
                       topic=topic,
                       gemini_api_key=gemini_api_key,
                       serp_api_key=serp_api_key,
                       similarity_threshold=0.75
                      )
    print(topic)
    news = agent.process_news(num_links=4)
    NewsSummaries.append(news)

print("len(NewsSummaries)",len(NewsSummaries))
# Create classifier instance
classifier = NewsClassifier()

# Example usage - replace with your own articles
example_articles = NewsSummaries

# Classify articles
results_df = classifier.classify_multiple(example_articles)
# Step 1: Generate Image using Pollinations API
j=-1
for i in unique_news_indices:
    j+=1
    prompt = df[i]["description"]
    api_url = f"https://image.pollinations.ai/prompt/{prompt}"
    
    # Send request
    response = requests.get(api_url)
    
    # Define file paths
    cropped_image_path = f"Images/{j}.jpg"
    
    # Check response status
    if response.status_code == 200:
        # Load image from response
        image = Image.open(BytesIO(response.content))
        width, height = image.size
        crop_area = (0, 0, width, height - 60)  # Adjust -50 if needed
    
        # Crop and save
        cropped_image = image.crop(crop_area)
        cropped_image.save(cropped_image_path)

    else:
        print(f"‚ùå Image generation failed. Status Code: {response.status_code}")

imgBB_api_key="72b3ca29b437df09340f3e132671e4f4"
image_urls=[]
for i  in range(j+1): 
    uploader = ImgBBUploader(api_key=imgBB_api_key)
    result = uploader.upload_image(f"Images/{i}.jpg")
    if result:
        image_urls.append(result['direct_url'])
        # results_df['image_url'][j]=result['direct_url']
    else:
        image_urls.append(" ")

results_df['image_urls']=image_urls        
# Display results in a nice format
# display(HTML(results_df[['text', 'category', 'confidence']].to_html(index=False)))

# # Plot visualizations
# classifier.plot_results(results_df)

out = results_df.drop(columns =['all_scores','confidence'] )
out.to_json('New_News.json', orient='records', indent=4)

import os
import json
import pandas as pd
# Define the file name

file_name = 'News.json'
file_name1 = 'News_list.json'

# Check if the file already exists
if not os.path.exists(file_name):
    # Create an empty JSON object
    data = []

    # Write the empty JSON object to the file
    with open(file_name, 'w') as file:
        json.dump(data, file, indent=4)

if not os.path.exists("News_list.json"):
    # Create an empty JSON object
    data = []
    # Write the empty JSON object to the file
    with open(file_name1, 'w') as file:
        json.dump(data, file, indent=4)
      
def merge_json_files():
    """
    Merge NewNews.json and News.json using pandas,
    where News.json content is appended below NewNews.json content.
    Final output is saved to News.json
    """
    print("mai andar aagya")
    try:
        # Read both JSON files into pandas DataFrames
        df_new = pd.read_json('New_News.json')
        df_existing = pd.read_json('News_list.json')
        
        # Concatenate with new content first, existing content second
        merged_df = pd.concat([df_new, df_existing], ignore_index=True)
        
        # Save to News.json using the specified format
        merged_df.to_json('News_list.json', orient='records', indent=4)
        json_data = merged_df.to_dict(orient='records')
        wrapped_data = {
            "news": json_data
        }
        
        with open('News.json', 'w') as file:
            json.dump(wrapped_data, file, indent=4)
        
        print("Successfully merged files and saved to News.json")
        
    except Exception as e:
        print(f"Error occurred: {str(e)}")

merge_json_files()
NEWS_FILE = os.path.join(os.path.dirname(__file__), "News.json")

@app.route("/news", methods=["GET"])
def get_news():
    if not os.path.exists(NEWS_FILE):
        return jsonify({"error": "News file not found"}), 404

    with open(NEWS_FILE, "r", encoding="utf-8") as file:
        try:
            news_data = json.load(file)
        except json.JSONDecodeError:
            return jsonify({"error": "Invalid JSON format"}), 500

    return jsonify(news_data)

print('aagya')
if __name__ == "__main__":
    app.run(debug=False)  # Change to debug=False in production
